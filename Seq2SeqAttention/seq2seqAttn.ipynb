{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'eng-fra.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cb9aa2865b19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eng-fra.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0meng_fre_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eng-fra.txt'"
     ]
    }
   ],
   "source": [
    "with open('eng-fra.txt', encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "eng_fre_pairs = []\n",
    "for line in content:\n",
    "    line = re.sub ('\\u202f', '', line)\n",
    "    line = line.strip('\\n').split('\\t')\n",
    "    eng_fre_pairs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eng_fre_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "for i, pair in enumerate(eng_fre_pairs):\n",
    "    if i%5 == 0:\n",
    "        test.append(pair)\n",
    "    elif i%17 == 0:\n",
    "        val.append(pair)\n",
    "    else:\n",
    "        train.append(pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy for tokenizing words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download\n",
    "# ! python -m spacy download fr\n",
    "# ! python -m spacy download en\n",
    "eng_lm = spacy.load('en')\n",
    "fre_lm = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating word(token) 2 index and index 2 word dictionaries for better access and dynamic output equivalance of train token index outputs to val and test tokens during loss calculation ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_list(data):\n",
    "    tokens_eng1 = list(dict.fromkeys([tok.text for tok in eng_lm.tokenizer(\" \".join(i[0] for i in data))]))\n",
    "    tokens_eng1.insert(0, '<sos>')\n",
    "    tokens_eng1.insert(1, '<eos>')\n",
    "    tokens_eng1.insert(2, '<unk>')\n",
    "    tokens_fre1 = list(dict.fromkeys([tok.text for tok in fre_lm.tokenizer(\" \".join(i[1] for i in data))]))\n",
    "    tokens_fre1.insert(0, '<sos>')\n",
    "    tokens_fre1.insert(1, '<eos>')\n",
    "    tokens_fre1.insert(2, '<unk>')\n",
    "    return tokens_eng1, tokens_fre1\n",
    "\n",
    "tokens_eng_train, tokens_fre_train = tokenize_list(train)\n",
    "tokens_eng_val, tokens_fre_val = tokenize_list(val)\n",
    "tokens_eng_test, tokens_fre_test = tokenize_list(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_index(token_list):\n",
    "    w2i = {tok : i for i, tok in enumerate(token_list)}\n",
    "    i2w = dict([(value, key) for key, value in w2i.items()])\n",
    "    return w2i, i2w\n",
    "\n",
    "w2i_eng_train, i2w_eng_train = token_index(tokens_eng_train)\n",
    "w2i_eng_val, i2w_eng_val = token_index(tokens_eng_val)\n",
    "w2i_eng_test, i2w_eng_test  = token_index(tokens_eng_test)\n",
    "\n",
    "w2i_fre_train, i2w_fre_train = token_index(tokens_fre_train)\n",
    "w2i_fre_val, i2w_fre_val = token_index(tokens_fre_val)\n",
    "w2i_fre_test, i2w_fre_test = token_index(tokens_fre_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Length : train {}, val {}, test {} \".format(len(train), len(val), len(test)))\n",
    "print(\" Percentage split : train {}, val {}, test {} \".format(len(train)/len(eng_fre_pairs)*100, len(val)/len(eng_fre_pairs)*100, len(test)/len(eng_fre_pairs) *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Data initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translation(Dataset):\n",
    "    \n",
    "    def __init__(self, eng_fre_data, eng_indeces, fre_indeces):\n",
    "\n",
    "        #can either be train, val or test depending on the loader\n",
    "        self.data = eng_fre_data \n",
    "        \n",
    "        self.eng_indeces = eng_indeces\n",
    "        self.fre_indeces = fre_indeces\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        input_tknzd = eng_lm.tokenizer(self.data[index][0])\n",
    "        label_tknzd = fre_lm.tokenizer(self.data[index][1])\n",
    "        \n",
    "        input_indeces = [self.eng_indeces['<sos>']]    \n",
    "        input_indeces[1:] = [self.eng_indeces[str(tok)] if str(tok) in \n",
    "                             self.eng_indeces else self.eng_indeces['<unk>'] for tok in input_tknzd]\n",
    "        input_indeces.append(self.eng_indeces['<eos>'])\n",
    "        \n",
    "        label_indeces = [self.fre_indeces['<sos>']]\n",
    "        label_indeces[1:] = [self.fre_indeces[str(tok)] if str(tok) in \n",
    "                             self.fre_indeces else self.fre_indeces['<unk>'] for tok in label_tknzd]\n",
    "        label_indeces.append(self.fre_indeces['<eos>'])\n",
    "        \n",
    "        return torch.LongTensor(input_indeces), torch.LongTensor(label_indeces)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "\n",
    "#  Dynamically varying batch shape conditioned on the max seqlen of an input in batch\n",
    "def collate_fn(data):\n",
    "    batch_inputs, batch_labels = zip(*data)\n",
    "    \n",
    "    inp_len = [len(inp) for inp in batch_inputs]\n",
    "    label_len = [len(label) for label in batch_labels]\n",
    "    \n",
    "    inputs = torch.zeros((len(batch_inputs), max(inp_len)), dtype = torch.int64)\n",
    "    labels = torch.zeros((len(batch_labels), max(label_len)), dtype = torch.int64)\n",
    "    \n",
    "    for i, inp in enumerate(batch_inputs):\n",
    "        inputs[i, :len(inp)] = inp\n",
    "    for i, label in enumerate(batch_labels):\n",
    "        labels[i, :len(label)] = label\n",
    "    \n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Architecture\n",
    "(Attention - based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp_vocab_dim, enc_hid_dim, embed_dim, dec_hid_dim, drop_prob):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(inp_vocab_dim, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        # concatenate two bidirectional hidden vectors and pass through a linear layer to generate one hidden \n",
    "        # vector of decoder hidden size\n",
    "        self.linear = nn.Linear(enc_hid_dim*2, dec_hid_dim) \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "    def forward(self, inp_sntc):\n",
    "\n",
    "        inp_embed = self.dropout(self.embed(inp_sntc))\n",
    "        outputs, hidden = self.gru(inp_embed)\n",
    "\n",
    "        open_hidden = torch.cat((hidden[0, :, :], hidden[1, :, :]), dim = 1)\n",
    "        hidden = torch.tanh(self.linear(open_hidden))\n",
    "        \n",
    "        return outputs, hidden   \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.sim = nn.Linear((enc_hid_dim*2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.weight = nn.Parameter(torch.rand(dec_hid_dim))\n",
    "        \n",
    "    def forward(self, curr_dec_hid, enc_outputs):\n",
    "        \n",
    "        sntc_length = enc_outputs.shape[0]\n",
    "        batch_size = enc_outputs.shape[1]\n",
    "        \n",
    "        curr_dec_hid = curr_dec_hid.unsqueeze(1).repeat(1, sntc_length, 1) \n",
    "        enc_outputs =  enc_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        e = torch.tanh(self.sim(torch.cat((curr_dec_hid, enc_outputs), dim = 2))) \n",
    "        e = e.permute(0, 2, 1)\n",
    "\n",
    "        weight = self.weight.repeat(batch_size, 1).unsqueeze(1)\n",
    "\n",
    "        attn_dist = torch.bmm(weight, e).squeeze(1)\n",
    "        norm_attn = torch.softmax(attn_dist, dim = 1)\n",
    "        \n",
    "        return norm_attn\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_dim, embed_dim, attn, enc_hid_dim, dec_hid_dim, drop_prob ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_dim, embed_dim)\n",
    "        self.attn = attn\n",
    "        \n",
    "        self.vocab_dim = vocab_dim\n",
    "        self.gru = nn.GRU((enc_hid_dim*2) + embed_dim, dec_hid_dim)\n",
    "        \n",
    "        self.linear = nn.Linear(enc_hid_dim*2 + dec_hid_dim + embed_dim, vocab_dim)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "    \n",
    "    def forward(self, inp, dec_hidden, enc_outputs):\n",
    "        \n",
    "        inp = inp.unsqueeze(0)\n",
    "        embedding = self.dropout(self.embed(inp))\n",
    "        \n",
    "        norm_attn = self.attn(dec_hidden, enc_outputs)    \n",
    "        norm_attn = norm_attn.unsqueeze(1)\n",
    "        \n",
    "        enc_outputs = enc_outputs.permute(1, 0, 2)\n",
    "\n",
    "        weighted_sum = torch.bmm(norm_attn, enc_outputs)\n",
    "        weighted_sum = weighted_sum.permute(1, 0, 2)\n",
    "\n",
    "        output, hidden = self.gru(torch.cat((embedding, weighted_sum), dim = 2), dec_hidden.unsqueeze(0) )\n",
    "        \n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedding = embedding.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted_sum = weighted_sum.squeeze(0)\n",
    "        \n",
    "        next_word = self.linear(torch.cat((output, weighted_sum, embedding), dim = 1))\n",
    "        \n",
    "        return next_word, hidden.squeeze(0)\n",
    "\n",
    "class seq2seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, device, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, sntc_input, sntc_label, thresh = 0.5):\n",
    "        \n",
    "        sntc_input = sntc_input.permute(1, 0)\n",
    "        sntc_label = sntc_label.permute(1, 0)\n",
    "        \n",
    "        enc_outputs, hidden = self.encoder(sntc_input)\n",
    "        \n",
    "        label_len = sntc_label.shape[0]\n",
    "        batch_size = sntc_input.shape[1]\n",
    "\n",
    "        vocab_dim = self.decoder.vocab_dim\n",
    "        \n",
    "        dec_outputs = torch.zeros(label_len, batch_size, vocab_dim).to(self.device)\n",
    "        input_word = sntc_label[0, :]\n",
    "        \n",
    "        for i in range(1, label_len):\n",
    "            output, hidden = self.decoder(input_word, hidden, enc_outputs)\n",
    "            dec_outputs[i] = output\n",
    "            pred_next_word = output.argmax(1)\n",
    "            input_word = sntc_label[i] if random.random() < thresh else pred_next_word\n",
    "        \n",
    "        return dec_outputs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_vocab_dim = len(w2i_eng_train)\n",
    "enc_hid_dim = 512\n",
    "embed_dim = 256\n",
    "dec_hid_dim = 512\n",
    "drop_prob = 0.5\n",
    "label_vocab_dim = len(w2i_fre_train)\n",
    "enc = Encoder(inp_vocab_dim, enc_hid_dim, embed_dim, dec_hid_dim, drop_prob)\n",
    "attn = Attention(enc_hid_dim, dec_hid_dim)\n",
    "dec = Decoder(label_vocab_dim, embed_dim, attn, enc_hid_dim, dec_hid_dim, drop_prob)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean = 0, std = 0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model = seq2seq(device, enc, dec).to(device)\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "epochs = 2\n",
    "batch_size = 100\n",
    "best_loss = float('inf')\n",
    "\n",
    "def val_test(model, data_loader, criterion, status):\n",
    "        \n",
    "        total_loss = 0\n",
    "        model.eval()\n",
    "        \n",
    "        for inp, label in data_loader:\n",
    "\n",
    "#             for token equivalence btw train and val or test\n",
    "            if status == 'val' :\n",
    "                for i in range(len(inp)):\n",
    "                    inp[i, :] = torch.LongTensor( [w2i_eng_train[i2w_eng_val[w_i.item()]] if i2w_eng_val[w_i.item()] in w2i_eng_train  \n",
    "                                     else w2i_eng_train['<unk>'] for w_i in list(inp[i, :])])\n",
    "\n",
    "                for i in range(len(label)):\n",
    "                    label[i, :] = torch.LongTensor([w2i_fre_train[i2w_fre_val[w_i.item()]] if i2w_fre_val[w_i.item()] in w2i_fre_train  \n",
    "                                     else w2i_fre_train['<unk>'] for w_i in list(label[i, :])])\n",
    "\n",
    "            if status == 'test':\n",
    "                for i in range(len(inp)):\n",
    "                    inp[i, :] = torch.LongTensor( [w2i_eng_train[i2w_eng_test[w_i.item()]] if i2w_eng_test[w_i.item()] in w2i_eng_train  \n",
    "                                     else w2i_eng_train['<unk>'] for w_i in list(inp[i, :])])\n",
    "\n",
    "                for i in range(len(label)):\n",
    "                    label[i, :] = torch.LongTensor([w2i_fre_train[i2w_fre_test[w_i.item()]] if i2w_fre_test[w_i.item()] in w2i_fre_train  \n",
    "                                     else w2i_fre_train['<unk>'] for w_i in list(label[i, :])])\n",
    "\n",
    "            inp = inp.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(inp, label)\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "\n",
    "            label = label.permute(1, 0)\n",
    "            label = label[1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    trans_data = Translation(train, w2i_eng_train, w2i_fre_train)\n",
    "    trans_data_val =  Translation(val, w2i_eng_val, w2i_fre_val)\n",
    "    trans_data_test =  Translation(test, w2i_eng_test, w2i_fre_test)\n",
    "    \n",
    "    data_loader_train = DataLoader(dataset = trans_data, batch_size = batch_size,\n",
    "                                   shuffle = False,  collate_fn = collate_fn)\n",
    "    data_loader_val = DataLoader(dataset = trans_data_val, batch_size = batch_size,\n",
    "                                shuffle = False, collate_fn = collate_fn)\n",
    "    data_loader_test = DataLoader(dataset = trans_data_test, batch_size = batch_size,\n",
    "                                shuffle = False, collate_fn = collate_fn)\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for inp, label in tqdm(data_loader_train):\n",
    "        inp = inp.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(inp, label)\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        label = label.permute(1, 0)\n",
    "        label = label[1:].reshape(-1)\n",
    "        \n",
    "        try:\n",
    "            loss = criterion(output, label)\n",
    "        except:\n",
    "            print(output.shape, label.shape)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() \n",
    "    \n",
    "    val_loss = val_test(model, data_loader_val, criterion, 'val')      \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'attn_seq2seq.pth')\n",
    "    print('Epoch : ', epoch)\n",
    "    print('Train loss per-input : ', train_loss/len(data_loader_train))\n",
    "    print('Val loss per-input : ', val_loss/len(data_loader_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = val_test(model, data_loader_test, criterion, 'test') \n",
    "print('Test loss per-input : ', test_loss/len(data_loader_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Val loss - decreasing every epoch - generalizing well\n",
    "#### Test loss - considerably low for just 4 epochs. ( Further analysis, below )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "###  1) Translation outputs analysis\n",
    "###  2) Attention effect\n",
    "###  3) robustness check - well devised adversarial samples probably\n",
    "###  4) Long term dependancy check - long sentences performance essentially\n",
    "###  5) Sentence structure check - grammar etc. thru metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
